{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c72c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\kevin\\anaconda3\\lib\\site-packages (7.5.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\kevin\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: Datetime in c:\\users\\kevin\\anaconda3\\lib\\site-packages (4.3)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from Datetime) (5.3.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from Datetime) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from praw) (1.2.3)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from praw) (2.3.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (4.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from zope.interface->Datetime) (52.0.0.post20210125)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw pandas Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a950b274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psaw in c:\\users\\kevin\\anaconda3\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from psaw) (2.25.1)\n",
      "Requirement already satisfied: Click in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from psaw) (7.1.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from requests->psaw) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from requests->psaw) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from requests->psaw) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from requests->psaw) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install psaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7556319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# IMPORT PACKAGES\n",
    "#######\n",
    "\n",
    "import numpy as np\n",
    "import praw\n",
    "import pandas as pd\n",
    "import praw\n",
    "import datetime as dt\n",
    "from psaw import PushshiftAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0dfeb",
   "metadata": {},
   "source": [
    "This dataset gathered data from Reddit using praw (The Python Reddit API Wrapper).\n",
    "The API connection process is conducted under the guidence from the link below:\n",
    "\n",
    "https://praw.readthedocs.io/en/latest/getting_started/quick_start.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325e70a",
   "metadata": {},
   "source": [
    "Your username is: yyd859\n",
    "Your password is: 54804839\n",
    "Your app's client ID is: XRBFUnVyp6VVdknjdodIKQ\n",
    "Your app's client secret is: rPqYL1OJMiKoek-7VGWOHoQvFbUfpQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434907f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=\"py7oUpDf56La0_Ojlu5KdA\",#my client id\n",
    "                     client_secret=\"NM62VVfQYh_O-9N_Mcpb60fz63KLZw\",  #your client secret\n",
    "                     user_agent=\"windows:script_mqm_winter.app:v0.1(by /u/YUMIinthefield)\", #user agent name\n",
    "                     username = \"YUMIinthefield\",     # your reddit username\n",
    "                     password = \"KCkc980415\")     # your reddit password\n",
    "# Use PushshiftAPI\n",
    "api = PushshiftAPI(reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a105ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612067964.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Acessing the reddit api\n",
    "s = 'wallstreetbets'   # make a list of subreddits you want to scrape the data from\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "#   CREATING DICTIONARY TO STORE THE DATA WHICH WILL BE CONVERTED TO A DATAFRAME\n",
    "########################################\n",
    "\n",
    "#   NOTE: ALL THE POST DATA AND COMMENT DATA WILL BE SAVED IN TWO DIFFERENT\n",
    "#   DATASETS AND LATER CAN BE MAPPED USING IDS OF POSTS/COMMENTS AS WE WILL \n",
    "#   BE CAPTURING ALL IDS THAT COME IN OUR WAY\n",
    "\n",
    "# SCRAPING CAN BE DONE VIA VARIOUS STRATEGIES {HOT,TOP,etc} we will go with keyword strategy i.e using search a keyword\n",
    "query = 'GME'\n",
    "#search by relevance\n",
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "\n",
    "\n",
    "##1\n",
    "end_epoch_1=int(dt.datetime(2021, 1, 31).timestamp())\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_1\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a1cce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612066987.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612067963\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_2\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77328435-def4-4efb-b1f1-4f8918f09d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612065650.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612066986\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_3\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af798eac-f237-49db-aafa-109df3d6c16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612064739.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612065649\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_4\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a6d9110-c081-405c-a50f-acedcf030296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612063989.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612064738\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_5\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b6bb587-68b7-4a75-a458-c4c82616ccbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612063081.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612063988\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_6\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9771338d-0991-4b88-a731-7c0b510ebf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612062102.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612063080\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_7\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "743f6467-fd66-4dc0-ba96-7608d837abf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612061280.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612062101\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_8\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34ba8be0-ff4f-41ee-9256-04fbdf6a1213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612060409.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612061279\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_9\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2beb8574-9a1b-4e99-a9b4-26fe4fb5cae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612059458.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612060408\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_10\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8a70430-ef7e-4576-97f4-fa5177d35483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612058485.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612059457\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_11\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56056f06-3192-4a58-8838-5ec5713bab86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612057438.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612058484\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_12\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ad678fb-b09a-477f-8fd1-d24890063cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612056593.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612057437\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_13\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73413fdb-10cc-4c64-8617-71e0ca8184a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612055812.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612056592\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_14\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2945f09f-5c96-4b39-8c9f-cd3e18a40533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612054978.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612055811\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_15\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abb126a9-7345-4a4d-995a-30cb945196b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612054132.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612054978\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_16\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3d3a4db-5363-4d4e-8a98-3142ff3f8b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612053352.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612054131\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_17\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e38cf628-fbb5-4a78-95bb-dc502328eb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612052676.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612053351\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_18\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96df93a9-cc53-4fac-b6da-16dbdcf5b3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612051967.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612052675\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_19\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b5b9c91-4f17-4480-9f3c-996683ff62dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612051102.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612051966\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_20\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bb3b2a9-956e-4cff-ab44-0bd322314ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612050294.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612051102\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_21\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e4a6190-e581-423f-952c-349cabeae030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612049551.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612050293\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_22\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "951fabfd-7822-4c58-b210-4dcf02ecc927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612048773.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612049550\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_23\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a63dd0a0-7b7f-4fea-9589-bb893df63a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612047853.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612048772\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_24\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "113b4421-2b79-4f9d-9efd-af00ad53c19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612047132.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612047852\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_25\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d32beee-8f3f-4b63-bc7f-172e7a7375a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612046320.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612047131\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_26\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dda5fa18-735a-406b-824a-9e80034fc589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612045615.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612046319\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_27\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad2f89df-6750-4329-b4de-530048a7df57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612044943.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612045614\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_28\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58129664-5350-4727-af36-54d06c1d416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612044152.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612044942\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_29\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60271902-6444-4b27-b6b1-20905b59315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612043485.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612044151\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_30\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc35426a-562c-4094-9bc7-5e19daef38a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612042817.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612043484\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_31\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d6b7e64-aa2e-46f4-8656-acd02b159276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612042080.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612042816\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_32\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24308de3-4353-454c-a7fb-07830401eedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612041509.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612042079\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_33\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0cfd0c1d-b4e8-478c-93a4-46a2a6bf3b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612040812.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612041508\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_34\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7db2ffc8-8b45-444f-998e-a27f862a2c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612040039.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612040811\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_35\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8a1e581-ce33-465f-851f-461e3a0c950b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612039405.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612040038\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_36\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "272d01ad-fc36-4b5b-84dc-a64229fcbbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612038608.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612039404\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_37\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b66f1bc-52fc-4cc1-a9bf-230a0d29ac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612037885.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612038607\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_38\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c10da27-6d2c-4fce-abbb-224ccc8ce9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612037156.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612037884\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_39\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b514c4fe-b0d4-49d3-af3d-74c31a34a482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612036683.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612037155\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_40\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "683193ba-9f16-4f7a-9d1f-3c0f568571ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612035847.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612036682\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_41\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "609751f6-c373-4bde-b8a3-66eff4cfa8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612035264.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612035846\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_42\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d993e8a2-1ef6-47a2-bc9c-c4c5fa49b40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612034637.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612035263\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_43\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e90a238-a888-4a31-a6a8-a8c5293c7553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612033845.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612034636\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_44\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94d9b143-680b-4a5e-8718-5a19082b923e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612033146.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612033844\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_45\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb983e5e-0543-465b-baba-d5b34dcc3ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612032436.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612033145\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_46\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84a020b6-3879-40ba-8208-a54c85c24f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612031576.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612032435\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_47\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "090571f6-7a6e-44ab-abf7-20603b0bd160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612030982.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612031575\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_48\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3329977-2d2e-40dd-b40a-b430871c9930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612030432.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612030982\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_49\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "447384b9-36d9-420a-b975-3f163d977ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612029710.0\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612030431\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_50\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f6df6-cb95-444d-8248-57eb89b7d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612037884\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_51\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4237d79-e8cb-4c61-ae93-4864a35aa3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612037884\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_52\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e702f0-b0e4-417f-a8fa-f08dae0563a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612037884\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_53\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f3933-9a0b-4c19-94c1-a4959a2a7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_score\":[],\n",
    "            \"comment_subreddit\":[],\n",
    "            \"comment_time_stamp\":[],\n",
    "            \"post_time_stamp\":[]\n",
    "        } \n",
    "end_epoch_1=1612037884\n",
    "sub=api.search_submissions(q=query,\n",
    "                            before=end_epoch_1,\n",
    "                            sort=\"desc\",\n",
    "                            subreddit=s,\n",
    "                            limit=100)\n",
    "            ##### Acessing comments on the post\n",
    "for submission in sub:\n",
    "    submission.comments.replace_more(limit = 1)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_dict[\"comment_id\"].append(comment.id)\n",
    "        comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "        comments_dict[\"comment_body\"].append(comment.body)\n",
    "        comments_dict[\"comment_score\"].append(comment.score)\n",
    "        comments_dict[\"comment_subreddit\"].append(s)\n",
    "        comments_dict[\"comment_time_stamp\"].append(comment.created_utc)\n",
    "        comments_dict[\"post_time_stamp\"].append(submission.created_utc)\n",
    "end_epoch_min=min(comments_dict[\"post_time_stamp\"])\n",
    "print(end_epoch_min)\n",
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "post_comments.to_csv(s+\"_comments_before_\"+ query +\"_54\"+\"_subreddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c43b27c-f39b-4bb4-a3cc-01c0dbaa1343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e80d31-fbbb-401c-9828-a0a8679aff62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d9dff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simply merge\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path = \"/Users/yyd/Documents/GitHub/RedditIPO-SentimentAnalysis/Code\"\n",
    "\n",
    "\n",
    "comments_files = glob.glob(os.path.join(path, \"*_comments_*.csv\"))\n",
    "df_from_each_file = (pd.read_csv(f, sep=',') for f in comments_files)\n",
    "df_merged   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "df_merged.to_csv( \"comments.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccddee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate\n",
    "comments_raw=pd.read_csv(\"/Users/yyd/Documents/GitHub/RedditIPO-SentimentAnalysis/Code/comments.csv\")\n",
    "comments_rd=comments_raw.drop_duplicates(subset='comment_id')\n",
    "comments_rd.to_csv( \"comments_rd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c8d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "    post_comments.to_csv(s+\"_comments_relevance_\"+ query +\"_subreddit.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

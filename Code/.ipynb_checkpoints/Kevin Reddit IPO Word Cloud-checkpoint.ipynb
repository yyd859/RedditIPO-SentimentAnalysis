{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61ee84b6-6413-4330-90ad-fd00d889dc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\kevin\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from wordcloud) (3.3.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from wordcloud) (8.2.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from wordcloud) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\kevin\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ee4c2f-f679-4ec4-9637-03b5927a2c91",
   "metadata": {},
   "source": [
    "# Packages and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ba6688c4-ad5b-4b10-8b6c-3c3b75ccd1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from string import digits\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "500dd145-1d88-4f12-bc84-56713f69df76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kevin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kevin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c9d96d6-b227-4fea-a080-8f7d69836f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"C:/Users/kevin/OneDrive/Winter Case Competition/RedditIPO-SentimentAnalysis/Data\"\n",
    "os.chdir(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e06b1a6-fa33-411a-b12f-cd19653d82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading text\n",
    "posts = pd.read_csv('posts_rd.csv')\n",
    "comments = pd.read_csv('comments_rd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d98bb9-3e1b-42f4-91eb-95bfde3bd69f",
   "metadata": {},
   "source": [
    "## A few check points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1592e4a-f31a-4f5c-b6ef-929fcc109cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(12/27) Monday's Pre-Market Stock Movers &amp; News</td>\n",
       "      <td>60</td>\n",
       "      <td>rpn6u5</td>\n",
       "      <td>https://www.reddit.com/r/StockMarket/comments/...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.640611e+09</td>\n",
       "      <td># Good Monday morning traders and investors of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(12/15) Wednesday's Pre-Market Stock Movers &amp; ...</td>\n",
       "      <td>25</td>\n",
       "      <td>rgzir5</td>\n",
       "      <td>https://www.reddit.com/r/StockMarket/comments/...</td>\n",
       "      <td>17</td>\n",
       "      <td>1.639576e+09</td>\n",
       "      <td>#Good morning traders and investors of the r/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>(12/13) Monday's Pre-Market Stock Movers &amp; News</td>\n",
       "      <td>15</td>\n",
       "      <td>rffrcz</td>\n",
       "      <td>https://www.reddit.com/r/StockMarket/comments/...</td>\n",
       "      <td>18</td>\n",
       "      <td>1.639402e+09</td>\n",
       "      <td># Good Monday morning traders and investors of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Reddit Files Confidentially for IPO. As of Aug...</td>\n",
       "      <td>15</td>\n",
       "      <td>rhlfnx</td>\n",
       "      <td>https://www.wsj.com/articles/reddit-files-pape...</td>\n",
       "      <td>16</td>\n",
       "      <td>1.639639e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>(12/14) Tuesday's Pre-Market Stock Movers &amp; News</td>\n",
       "      <td>13</td>\n",
       "      <td>rg793x</td>\n",
       "      <td>https://www.reddit.com/r/StockMarket/comments/...</td>\n",
       "      <td>25</td>\n",
       "      <td>1.639488e+09</td>\n",
       "      <td>#Good morning traders and investors of the r/S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  \\\n",
       "0           0             0               0   \n",
       "1           1             1               1   \n",
       "2           2             2               2   \n",
       "3           3             3               3   \n",
       "4           4             4               4   \n",
       "\n",
       "                                               title  score      id  \\\n",
       "0    (12/27) Monday's Pre-Market Stock Movers & News     60  rpn6u5   \n",
       "1  (12/15) Wednesday's Pre-Market Stock Movers & ...     25  rgzir5   \n",
       "2    (12/13) Monday's Pre-Market Stock Movers & News     15  rffrcz   \n",
       "3  Reddit Files Confidentially for IPO. As of Aug...     15  rhlfnx   \n",
       "4   (12/14) Tuesday's Pre-Market Stock Movers & News     13  rg793x   \n",
       "\n",
       "                                                 url  comms_num       created  \\\n",
       "0  https://www.reddit.com/r/StockMarket/comments/...          8  1.640611e+09   \n",
       "1  https://www.reddit.com/r/StockMarket/comments/...         17  1.639576e+09   \n",
       "2  https://www.reddit.com/r/StockMarket/comments/...         18  1.639402e+09   \n",
       "3  https://www.wsj.com/articles/reddit-files-pape...         16  1.639639e+09   \n",
       "4  https://www.reddit.com/r/StockMarket/comments/...         25  1.639488e+09   \n",
       "\n",
       "                                                body  \n",
       "0  # Good Monday morning traders and investors of...  \n",
       "1  #Good morning traders and investors of the r/S...  \n",
       "2  # Good Monday morning traders and investors of...  \n",
       "3                                                NaN  \n",
       "4  #Good morning traders and investors of the r/S...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9e30a86-fbd8-4f4e-9cf9-ee6ca002a6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_parent_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_link_id</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>comment_subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hor72d8</td>\n",
       "      <td>t3_rhlfnx</td>\n",
       "      <td>Deleting all comments and accounts in 3... 2.....</td>\n",
       "      <td>t3_rhlfnx</td>\n",
       "      <td>4</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>horfp4g</td>\n",
       "      <td>t3_rhlfnx</td>\n",
       "      <td>Make the first offering to the users bitch</td>\n",
       "      <td>t3_rhlfnx</td>\n",
       "      <td>2</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>horc0ki</td>\n",
       "      <td>t1_hor72d8</td>\n",
       "      <td>You joke. But, just another social media site ...</td>\n",
       "      <td>t3_rhlfnx</td>\n",
       "      <td>2</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>horebg5</td>\n",
       "      <td>t1_horc0ki</td>\n",
       "      <td>I only joke for now. Once it really happens, I...</td>\n",
       "      <td>t3_rhlfnx</td>\n",
       "      <td>2</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>hp8mmwv</td>\n",
       "      <td>t1_horebg5</td>\n",
       "      <td>We already are</td>\n",
       "      <td>t3_rhlfnx</td>\n",
       "      <td>1</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1 comment_id comment_parent_id  \\\n",
       "0           0             0               0    hor72d8         t3_rhlfnx   \n",
       "1           1             1               1    horfp4g         t3_rhlfnx   \n",
       "2           2             2               2    horc0ki        t1_hor72d8   \n",
       "3           3             3               3    horebg5        t1_horc0ki   \n",
       "4           4             4               4    hp8mmwv        t1_horebg5   \n",
       "\n",
       "                                        comment_body comment_link_id  \\\n",
       "0  Deleting all comments and accounts in 3... 2.....       t3_rhlfnx   \n",
       "1         Make the first offering to the users bitch       t3_rhlfnx   \n",
       "2  You joke. But, just another social media site ...       t3_rhlfnx   \n",
       "3  I only joke for now. Once it really happens, I...       t3_rhlfnx   \n",
       "4                                     We already are       t3_rhlfnx   \n",
       "\n",
       "   comment_score comment_subreddit  \n",
       "0              4       stockmarket  \n",
       "1              2       stockmarket  \n",
       "2              2       stockmarket  \n",
       "3              2       stockmarket  \n",
       "4              1       stockmarket  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5152802b-02b7-4433-9aaa-14f139d9bd8c",
   "metadata": {},
   "source": [
    "# Trim datafram to list & dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f371e7b3-de15-47e6-9bfa-40235df1b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_trimm = posts[['title', 'body']]\n",
    "comments_trimm = comments[['comment_body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8733ffb2-6e9e-47a8-b5b6-e6d4afaba857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(12/27) Monday's Pre-Market Stock Movers &amp; News</td>\n",
       "      <td># Good Monday morning traders and investors of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(12/15) Wednesday's Pre-Market Stock Movers &amp; ...</td>\n",
       "      <td>#Good morning traders and investors of the r/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(12/13) Monday's Pre-Market Stock Movers &amp; News</td>\n",
       "      <td># Good Monday morning traders and investors of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reddit Files Confidentially for IPO. As of Aug...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(12/14) Tuesday's Pre-Market Stock Movers &amp; News</td>\n",
       "      <td>#Good morning traders and investors of the r/S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0    (12/27) Monday's Pre-Market Stock Movers & News   \n",
       "1  (12/15) Wednesday's Pre-Market Stock Movers & ...   \n",
       "2    (12/13) Monday's Pre-Market Stock Movers & News   \n",
       "3  Reddit Files Confidentially for IPO. As of Aug...   \n",
       "4   (12/14) Tuesday's Pre-Market Stock Movers & News   \n",
       "\n",
       "                                                body  \n",
       "0  # Good Monday morning traders and investors of...  \n",
       "1  #Good morning traders and investors of the r/S...  \n",
       "2  # Good Monday morning traders and investors of...  \n",
       "3                                                NaN  \n",
       "4  #Good morning traders and investors of the r/S...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_trimm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09e5d41e-1f0c-4a79-baf8-a2d4e88953ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deleting all comments and accounts in 3... 2.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Make the first offering to the users bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You joke. But, just another social media site ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I only joke for now. Once it really happens, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We already are</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_body\n",
       "0  Deleting all comments and accounts in 3... 2.....\n",
       "1         Make the first offering to the users bitch\n",
       "2  You joke. But, just another social media site ...\n",
       "3  I only joke for now. Once it really happens, I...\n",
       "4                                     We already are"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_trimm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db800718-bfc7-48fe-8a99-f9ccbb1bfee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts\n",
    "posts_trimm = posts_trimm.to_string()\n",
    "comments_trimm = comments_trimm.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c26052c-a7b2-4964-9eae-293ff36666de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tonkenizer. Lemmatizer is used here to achieve full morphological analysis and accurately identify the lemma for each word, this is better than simply stemming. \n",
    "WNL = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d7275-b490-4652-a524-8b997f03b40b",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eb6b358d-ca45-4689-9320-9e1296293ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean up texts by transforming to lower case, also removing apostrophe\n",
    "def lowerRep(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    return text\n",
    "\n",
    "# removing number\n",
    "def removeNum(text):\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    text = text.translate(remove_digits)\n",
    "    return text\n",
    "\n",
    "# remove extra chars and stop words\n",
    "def removeChar(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    text1 = nltk.Text(tokens)\n",
    "    text_content = [''.join(re.split(\"[ .,;:!?‘’``''@#$%^_&*()<>{}~\\n\\t\\\\\\-]\", word)) for word in text1]\n",
    "    return text_content\n",
    "\n",
    "# remove URLs\n",
    "def removeURL(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "# initial removal of stopwords and empty spaces\n",
    "def removeSpace(text, stopwords):\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    text = [s for s in text if len(s) != 0]\n",
    "    return text\n",
    "\n",
    "# lemmatize\n",
    "def lemmatize(text):\n",
    "    text = [WNL.lemmatize(t) for t in text]\n",
    "    return text\n",
    "\n",
    "# tokenize\n",
    "def tokenize(text):\n",
    "    tokens = [nltk.word_tokenize(i) for i in text]\n",
    "    return tokens\n",
    "\n",
    "# bigrams dictionary\n",
    "def bigramDict(text):\n",
    "    bigrams_list = list(nltk.bigrams(text))\n",
    "    dictionary = [' '.join(tup) for tup in bigrams_list]\n",
    "    return dictionary\n",
    "\n",
    "# generate words frequency\n",
    "def wordsFreq(text):\n",
    "    vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "    bag_of_words = vectorizer.fit_transform(text)\n",
    "    vectorizer.vocabulary_\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "564b22bc-87b7-4032-8bbf-fcbadd6f6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_stopwords = list(STOPWORDS) + [\"https\", \"png\", \"imgur\", \"n\", \"CLICK\", \"reddit\", \"ashx\", \"will\", \"CHART\", \n",
    "                                     \"t\", \"ta\", \"st_c\", \"sma\", \"smsch_200p\", \"bb_20_2\", \"webp\", \"s\", \"l\", \n",
    "                                    \"stofu_b_14_3_3\", \"macd_b_12_26_9\", \"rsi_b_14\", \"sch_200p\", \"p\", \"d\", \"c\"]\n",
    "comments_stopwords = list(STOPWORDS) + [\"n\", \"nbsp\", \"http\", \"u\", \"s\", \"reddit\", \"will\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "72338282-e765-4f81-9c95-b46e57d8a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_trimm = removeURL(posts_trimm)\n",
    "posts_trimm = lowerRep(posts_trimm)\n",
    "posts_trimm = removeNum(posts_trimm)\n",
    "posts_content = removeChar(posts_trimm)\n",
    "posts_content = removeSpace(posts_content, posts_stopwords)\n",
    "posts_content = lemmatize(posts_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "15c25bb2-a816-41d6-b76c-87348b04e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_token = tokenize(posts_content)\n",
    "posts_bigram = bigramDict(posts_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9714f92e-24fe-4d57-bf43-02432ae82558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test only on posts; do not run for comment!\n",
    "print(posts_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8f0f0393-5fa7-485f-b967-1658edb8a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_word_freq = wordsFreq(posts_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41bfb68-e406-4838-a446-46bb659fd1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test only on posts; do not run for comment!\n",
    "print(posts_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "16b133e8-247c-4608-9053-af8cf36c94c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "741109b8-edb1-4e75-8cf1-0ea733b6e041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e94e36e-79a0-46bb-91cd-2d9855ebb0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e1478-ffbc-4ce5-9c77-9474a714331d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2ca41-366d-4623-9694-47a762971d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8eeaa137-c913-4dd3-88fa-00d4e3972bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_dict = dict(posts_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ca914e16-3e74-48b7-a5fb-a5eb2f881785",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_posts = WordCloud(\n",
    "        background_color = 'white',\n",
    "        stopwords = posts_stopwords,\n",
    "        height = 400,\n",
    "        width = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d34da-e0a4-4fa7-bd75-0aa5524010e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_comments = WordCloud(\n",
    "        background_color = 'white', \n",
    "        stopwords = comments_stopwords, \n",
    "        height = 400, \n",
    "        width = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "18be5dbe-ca56-45eb-a28d-1a6c1a48a44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x2872782e2e0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_posts.generate_from_frequencies(posts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d94b7-ccd4-4629-a6fc-7524abc25af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_comments.generate(comments_trimm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9f2d3ed4-0a6b-4265-a29a-eb729dc897b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x2872782e2e0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_posts.to_file('postwordcloudtry.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ab404-220c-41dc-8c3c-ccf966cb0ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_comments.to_file('commentwordcloudtry.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
